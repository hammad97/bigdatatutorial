{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "* 312441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\spark-3.3.0-bin-hadoop3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is required to run everytime because sometimes, \n",
    "# without running it it fails to establish connection back to python.\n",
    "import findspark\n",
    "import matplotlib.pyplot as plt\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+----------+\n",
      "|UserID|MovieID|              Rating| Timestamp|\n",
      "+------+-------+--------------------+----------+\n",
      "|    15|   4973|          excellent!|1215184630|\n",
      "|    20|   1747|            politics|1188263867|\n",
      "|    20|   1747|              satire|1188263867|\n",
      "|    20|   2424|     chick flick 212|1188263835|\n",
      "|    20|   2424|               hanks|1188263835|\n",
      "|    20|   2424|                ryan|1188263835|\n",
      "|    20|   2947|              action|1188263755|\n",
      "|    20|   2947|                bond|1188263756|\n",
      "|    20|   3033|               spoof|1188263880|\n",
      "|    20|   3033|           star wars|1188263880|\n",
      "|    20|   7438|              bloody|1188263801|\n",
      "|    20|   7438|             kung fu|1188263801|\n",
      "|    20|   7438|           Tarantino|1188263801|\n",
      "|    21|  55247|                   R|1205081506|\n",
      "|    21|  55253|               NC-17|1205081488|\n",
      "|    25|     50|        Kevin Spacey|1166101426|\n",
      "|    25|   6709|         Johnny Depp|1162147221|\n",
      "|    31|     65|        buddy comedy|1188263759|\n",
      "|    31|    546|strangely compelling|1188263674|\n",
      "|    31|   1091|         catastrophe|1188263741|\n",
      "+------+-------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import mean , stddev, col, to_date, date_format\n",
    "import pyspark.sql.functions as F\n",
    "from time import strptime\n",
    "import datetime\n",
    "from ast import literal_eval\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.functions import*\n",
    "\n",
    "# Spark configuration and reading + printing of tags data from movielens\n",
    "conf = pyspark.SparkConf().setAppName('ex8_2').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "tags_df = sc.textFile('tags.dat').map(lambda x: x.split(\"::\")).collect()\n",
    "rdd1 = sc.parallelize(tags_df).toDF()\n",
    "custom_tags = rdd1.withColumnRenamed(\"_1\", \"UserID\").withColumnRenamed(\"_2\", \"MovieID\").withColumnRenamed(\"_3\", \"Rating\").withColumnRenamed(\"_4\", \"Timestamp\")\n",
    "custom_tags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users seperate tag session: \n",
      "+------+-------+----------------+----------+---------+\n",
      "|UserID|MovieID|          Rating| Timestamp|SessionID|\n",
      "+------+-------+----------------+----------+---------+\n",
      "|  1000|    277|children's story|1188533111|        1|\n",
      "|  1000|   1994|    sci-fi. dark|1188533136|        1|\n",
      "|  1000|   5377|         romance|1188533150|        1|\n",
      "|  1000|   7147|    family bonds|1188533161|        1|\n",
      "|  1000|    362|animated classic|1188533171|        1|\n",
      "|  1000|    276|          family|1188533235|        1|\n",
      "| 10003|  42013|        Passable|1150432435|        1|\n",
      "| 10003|  51662|  FIOS on demand|1207953326|        2|\n",
      "| 10003|  54997|  FIOS on demand|1207953335|        2|\n",
      "| 10003|  55765|  FIOS on demand|1207953342|        2|\n",
      "| 10003|  55363|  FIOS on demand|1207953420|        2|\n",
      "| 10003|  56152|  FIOS on demand|1207953526|        2|\n",
      "| 10003|  55116|  FIOS on demand|1207953636|        2|\n",
      "| 10003|  56174|  FIOS on demand|1207953670|        2|\n",
      "| 10003|  55176|  FIOS on demand|1207953755|        2|\n",
      "| 10003|  55247|  FIOS on demand|1207953756|        2|\n",
      "| 10003|  54881|  FIOS on demand|1207953758|        2|\n",
      "| 10003|  55820|  FIOS on demand|1207953873|        2|\n",
      "| 10003|  53123|  FIOS on demand|1207953875|        2|\n",
      "| 10003|  53550|  FIOS on demand|1207953937|        2|\n",
      "+------+-------+----------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "# Here we first sort the data with timestamp and then add temporary column which just tells us in if\n",
    "# the user meets our duration condition and later we use this columns data to generate sessionId and get rid of temp column.\n",
    "user_timestamp = Window.partitionBy(\"UserID\").orderBy(\"Timestamp\")\n",
    "\n",
    "custom1 = custom_tags.withColumn(\"isGreaterDuration\", when(((col(\"Timestamp\") - lag(col(\"Timestamp\"), 1).over(user_timestamp)) > 1800), 1).when(((col(\"Timestamp\") - lag(col(\"Timestamp\"), 1).over(user_timestamp)) <= 1800), 0).otherwise(1))\n",
    "custom1 = custom1.withColumn('SessionID', (sum('isGreaterDuration').over(user_timestamp)).cast(\"bigint\"))\n",
    "custom1 = custom1.drop('isGreaterDuration')\n",
    "print('Users seperate tag session: ')\n",
    "custom1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of tagging per user session: \n",
      "+------+---------+---------+\n",
      "|UserID|SessionID|frequency|\n",
      "+------+---------+---------+\n",
      "|  1000|        1|        6|\n",
      "| 10003|        1|        1|\n",
      "| 10003|        2|       18|\n",
      "| 10003|        3|       38|\n",
      "| 10020|        1|        2|\n",
      "| 10025|        1|        1|\n",
      "| 10032|        1|       39|\n",
      "| 10032|        2|        1|\n",
      "| 10032|        3|        1|\n",
      "| 10032|        4|        1|\n",
      "| 10032|        5|        4|\n",
      "| 10032|        6|        1|\n",
      "| 10032|        7|        1|\n",
      "| 10032|        8|        4|\n",
      "| 10032|        9|        1|\n",
      "| 10032|       10|        1|\n",
      "| 10032|       11|        1|\n",
      "| 10032|       12|        1|\n",
      "| 10051|        1|        1|\n",
      "| 10058|        1|       35|\n",
      "+------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. \n",
    "# I simply use groupby on my previous df and sort it by sessionid generated earlier. Further use the count function\n",
    "# to finally get the frequency and add it to the df.\n",
    "custom2 = custom1.groupBy(custom1.UserID, custom1.SessionID).count().orderBy(['UserID', 'SessionID'], ascending = True)\n",
    "\n",
    "custom2 = custom2.withColumnRenamed(\"count\", \"frequency\")\n",
    "print('Frequency of tagging per user session: ')\n",
    "custom2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each user mean and std dev: \n",
      "+------+---------+---------+----------+------------+\n",
      "|UserID|SessionID|frequency|users_mean|users_stddev|\n",
      "+------+---------+---------+----------+------------+\n",
      "|  1000|        1|        6|       6.0|        null|\n",
      "| 10003|        1|        1|      19.0|    18.52026|\n",
      "| 10003|        2|       18|      19.0|    18.52026|\n",
      "| 10003|        3|       38|      19.0|    18.52026|\n",
      "| 10020|        1|        2|       2.0|        null|\n",
      "| 10025|        1|        1|       1.0|        null|\n",
      "| 10032|        1|       39| 4.6666665|   10.873933|\n",
      "| 10032|        2|        1| 4.6666665|   10.873933|\n",
      "| 10032|        3|        1| 4.6666665|   10.873933|\n",
      "| 10032|        4|        1| 4.6666665|   10.873933|\n",
      "| 10032|        5|        4| 4.6666665|   10.873933|\n",
      "| 10032|        6|        1| 4.6666665|   10.873933|\n",
      "| 10032|        7|        1| 4.6666665|   10.873933|\n",
      "| 10032|        8|        4| 4.6666665|   10.873933|\n",
      "| 10032|        9|        1| 4.6666665|   10.873933|\n",
      "| 10032|       10|        1| 4.6666665|   10.873933|\n",
      "| 10032|       11|        1| 4.6666665|   10.873933|\n",
      "| 10032|       12|        1| 4.6666665|   10.873933|\n",
      "| 10051|        1|        1|       1.0|        null|\n",
      "| 10058|        1|       35| 25.333334|   15.044379|\n",
      "+------+---------+---------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. \n",
    "# We start by first sorting with userid and then using frequency column just calculate the mean and std_dev\n",
    "# using the built-in functions and save them in new columns which are then printed.\n",
    "user_usergroup = Window.partitionBy(\"UserID\").orderBy(\"UserID\")\n",
    "\n",
    "custom3 = custom2.withColumn('users_mean', (mean('frequency').over(user_usergroup)).cast(\"float\")).orderBy(['UserID', 'SessionID'], ascending = True)\n",
    "custom3 = custom3.withColumn('users_stddev', (stddev('frequency').over(user_usergroup)).cast(\"float\")).orderBy(['UserID', 'SessionID'], ascending=True).replace(float('nan'), 0)\n",
    "print('Each user mean and std dev: ')\n",
    "custom3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean across users:  7.3\n",
      "Std dev accross users:  22.264\n"
     ]
    }
   ],
   "source": [
    "# 4.\n",
    "# In this case we have to find mean/stdev across users so not limited to each user and for that i take \n",
    "# mean/stddev of frequencies. Then just print the result\n",
    "mean_stddev_res = custom3.select(\n",
    "    mean(col('frequency')).alias('mean_f'),\n",
    "    stddev(col('frequency')).alias('stdev_f')\n",
    ").collect()\n",
    "np_mean, np_stdev = np.around(mean_stddev_res[0]['mean_f'], 3), np.around(mean_stddev_res[0]['stdev_f'], 3)\n",
    "print('Mean across users: ', np_mean)\n",
    "print('Std dev accross users: ', np_stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
